{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import io # modified for Python 2.7 MP\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWLINE = '\\n'\n",
    "\n",
    "HAM = 'ham'\n",
    "SPAM = 'spam'\n",
    "\n",
    "SOURCES = [\n",
    "    ('data/spam',        SPAM),\n",
    "    ('data/easy_ham',    HAM),\n",
    "    ('data/hard_ham',    HAM),\n",
    "]\n",
    "    \n",
    "SOURCES_ALL = [\n",
    "    ('data/spam',        SPAM),\n",
    "    ('data/easy_ham',    HAM),\n",
    "    ('data/hard_ham',    HAM),\n",
    "    ('data/beck-s',      HAM),\n",
    "    ('data/farmer-d',    HAM),\n",
    "    ('data/kaminski-v',  HAM),\n",
    "    ('data/kitchen-l',   HAM),\n",
    "    ('data/lokay-m',     HAM),\n",
    "    ('data/williams-w3', HAM),\n",
    "    ('data/BG',          SPAM),\n",
    "    ('data/GP',          SPAM),\n",
    "    ('data/SH',          SPAM)\n",
    "]\n",
    "\n",
    "SKIP_FILES = {'cmds'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    for root, dir_names, file_names in os.walk(path):\n",
    "        for path in dir_names:\n",
    "            read_files(os.path.join(root, path))\n",
    "        for file_name in file_names:\n",
    "            if file_name not in SKIP_FILES:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    past_header, lines = False, []\n",
    "                    f = io.open(file_path, encoding=\"latin-1\") # modified for Python 2.7 MP\n",
    "                    for line in f:\n",
    "                        if past_header:\n",
    "                            lines.append(line)\n",
    "                        elif line == NEWLINE:\n",
    "                            past_header = True\n",
    "                    f.close()\n",
    "                    content = NEWLINE.join(lines)\n",
    "                    yield file_path, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/4t8_qnxj42v8gqmhh22r_hs80000gn/T/ipykernel_47711/1979032172.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(build_data_frame(path, classification))\n",
      "/var/folders/t_/4t8_qnxj42v8gqmhh22r_hs80000gn/T/ipykernel_47711/1979032172.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(build_data_frame(path, classification))\n",
      "/var/folders/t_/4t8_qnxj42v8gqmhh22r_hs80000gn/T/ipykernel_47711/1979032172.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(build_data_frame(path, classification))\n"
     ]
    }
   ],
   "source": [
    "def build_data_frame(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for file_name, text in read_files(path):\n",
    "        rows.append({'text': text, 'class': classification})\n",
    "        index.append(file_name)\n",
    "\n",
    "    data_frame = DataFrame(rows, index=index)\n",
    "    return data_frame\n",
    "\n",
    "data = DataFrame({'text': [], 'class': []})\n",
    "for path, classification in SOURCES:\n",
    "    data = data.append(build_data_frame(path, classification))\n",
    "\n",
    "data = data.reindex(numpy.random.permutation(data.index))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer',   CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier',         MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/02197.8ff83816cea0884898d358cd0423b356</th>\n",
       "      <td>URL: http://boingboing.net/#85514221\\n\\nDate: ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/01100.3f3a79ad6a2cdd501aa86421fb5157a5</th>\n",
       "      <td>On Wed, Feb 06, 2002 at 04:30:18PM +0200, Harr...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/spam/00240.2ff7f745285653a238214d975859406b</th>\n",
       "      <td>\\n\\nDear Sir or Madam\\n\\n\\n\\nIn the past you h...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/02034.bd799f09b362a83731ae6931a7916caf</th>\n",
       "      <td>URL: http://www.askbjoernhansen.com/archives/2...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/01651.7cafcb2d9dcaadd665afabc65c267f36</th>\n",
       "      <td>\\n\\n    &gt;&gt; Ultimately I'd like to see tight in...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/02199.663c7327f5f9c7aa46d0fc56fbb68208</th>\n",
       "      <td>URL: http://diveintomark.org/archives/2002/10/...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/01341.34cf1021232db9d1c782888dcd1e5328</th>\n",
       "      <td>| \\n\\n| 0 hits here. :(\\n\\n| \\n\\n\\n\\nI also ge...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/01719.a401ddc61fc3d89fbaee70ea107a9956</th>\n",
       "      <td>[Neil Schemenauer]\\n\\n&gt; These results are from...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/01053.9f4c2fea143d25bf2680c444e547df55</th>\n",
       "      <td>\\n\\n--------------Boundary-00=_OYOXHTVA0T2X8R5...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/easy_ham/01374.5d5d21f3e389c6de699918082d008fac</th>\n",
       "      <td>\\n\\nOn Wednesday, August 28, 2002, at 01:50  P...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text  \\\n",
       "data/easy_ham/02197.8ff83816cea0884898d358cd042...  URL: http://boingboing.net/#85514221\\n\\nDate: ...   \n",
       "data/easy_ham/01100.3f3a79ad6a2cdd501aa86421fb5...  On Wed, Feb 06, 2002 at 04:30:18PM +0200, Harr...   \n",
       "data/spam/00240.2ff7f745285653a238214d975859406b    \\n\\nDear Sir or Madam\\n\\n\\n\\nIn the past you h...   \n",
       "data/easy_ham/02034.bd799f09b362a83731ae6931a79...  URL: http://www.askbjoernhansen.com/archives/2...   \n",
       "data/easy_ham/01651.7cafcb2d9dcaadd665afabc65c2...  \\n\\n    >> Ultimately I'd like to see tight in...   \n",
       "...                                                                                               ...   \n",
       "data/easy_ham/02199.663c7327f5f9c7aa46d0fc56fbb...  URL: http://diveintomark.org/archives/2002/10/...   \n",
       "data/easy_ham/01341.34cf1021232db9d1c782888dcd1...  | \\n\\n| 0 hits here. :(\\n\\n| \\n\\n\\n\\nI also ge...   \n",
       "data/easy_ham/01719.a401ddc61fc3d89fbaee70ea107...  [Neil Schemenauer]\\n\\n> These results are from...   \n",
       "data/easy_ham/01053.9f4c2fea143d25bf2680c444e54...  \\n\\n--------------Boundary-00=_OYOXHTVA0T2X8R5...   \n",
       "data/easy_ham/01374.5d5d21f3e389c6de699918082d0...  \\n\\nOn Wednesday, August 28, 2002, at 01:50  P...   \n",
       "\n",
       "                                                   class  \n",
       "data/easy_ham/02197.8ff83816cea0884898d358cd042...   ham  \n",
       "data/easy_ham/01100.3f3a79ad6a2cdd501aa86421fb5...   ham  \n",
       "data/spam/00240.2ff7f745285653a238214d975859406b    spam  \n",
       "data/easy_ham/02034.bd799f09b362a83731ae6931a79...   ham  \n",
       "data/easy_ham/01651.7cafcb2d9dcaadd665afabc65c2...   ham  \n",
       "...                                                  ...  \n",
       "data/easy_ham/02199.663c7327f5f9c7aa46d0fc56fbb...   ham  \n",
       "data/easy_ham/01341.34cf1021232db9d1c782888dcd1...   ham  \n",
       "data/easy_ham/01719.a401ddc61fc3d89fbaee70ea107...   ham  \n",
       "data/easy_ham/01053.9f4c2fea143d25bf2680c444e54...   ham  \n",
       "data/easy_ham/01374.5d5d21f3e389c6de699918082d0...   ham  \n",
       "\n",
       "[3250 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails classified: 3250\n",
      "Score: 0.9355973519816052\n",
      "Confusion matrix:\n",
      "[[2744    6]\n",
      " [  56  444]]\n"
     ]
    }
   ],
   "source": [
    "n = len(data)\n",
    "k_fold = KFold(n_splits=6)\n",
    "scores = []\n",
    "confusion = numpy.array([[0, 0], [0, 0]])\n",
    "for i,(train_indices, test_indices) in enumerate(k_fold.split(data)):\n",
    "    train_text = data.iloc[train_indices]['text'].values\n",
    "    train_y = data.iloc[train_indices]['class'].values.astype(str)\n",
    "\n",
    "    test_text = data.iloc[test_indices]['text'].values\n",
    "    test_y = data.iloc[test_indices]['class'].values.astype(str)\n",
    "\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=SPAM)\n",
    "    scores.append(score)\n",
    "\n",
    "print('Total emails classified:', len(data))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
